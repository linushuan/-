#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
AQI Tæª¢å®šçµ±è¨ˆåˆ†æå·¥å…· v1
åŠŸèƒ½ï¼š
 1. è¨ˆç®—å„å€åŸŸå¹³å‡å€¼
 2. é€²è¡Œå€åŸŸé–“çš„ T æª¢å®šï¼ˆå…©å…©æ¯”è¼ƒï¼‰
 3. è¼¸å‡ºçµ±è¨ˆçµæœè¡¨æ ¼å’Œè¦–è¦ºåŒ–åœ–è¡¨
 4. ç”Ÿæˆè©³ç´°çš„çµ±è¨ˆå ±å‘Š
"""

import os
import glob
import matplotlib as mpl
mpl.use('Agg')
mpl.rcParams['axes.unicode_minus'] = False

import matplotlib.pyplot as plt
import seaborn as sns
from matplotlib.font_manager import fontManager, FontProperties
import pandas as pd
import numpy as np
from scipy import stats
from itertools import combinations
from tqdm import tqdm
import warnings
warnings.filterwarnings('ignore')

# ---------- Config ----------
current_dir = os.path.dirname(os.path.abspath(__file__))
base_dir = os.path.join(current_dir, "data")
output_dir = os.path.join(current_dir, "ttest_results")
os.makedirs(output_dir, exist_ok=True)

# å€åŸŸå®šç¾©
areas = {
    "åŒ—": ["ä¸‰é‡", "ä¸­å£¢", "ä¸­å±±", "å†¬å±±", "å¤äº­", "åœŸåŸ", "åŸºéš†", "å£«æ—",
           "å¤§åœ’", "å®œè˜­", "å¹³é®", "æ–°åº—", "æ–°ç«¹", "æ–°èŠ", "æ¾å±±", "æ¿æ©‹",
           "æ—å£", "æ¡ƒåœ’", "æ°¸å’Œ", "æ±æ­¢", "æ·¡æ°´", "æ¹–å£", "ç«¹æ±", "èœå¯®",
           "è¬è¯", "è¬é‡Œ", "è§€éŸ³", "é™½æ˜", "é¾æ½­"],
    "ä¸­": ["ä¸‰ç¾©", "äºŒæ—", "å—æŠ•", "å¤§é‡Œ", "å½°åŒ–", "å¿ æ˜", "æ²™é¹¿",
           "ç·šè¥¿", "è‹—æ —", "è¥¿å±¯", "è±åŸ", "é ­ä»½"],
    "å—": ["ä»æ­¦", "å‰é‡‘", "å‰é®", "å–„åŒ–", "å˜‰ç¾©", "å¤§å¯®", "å®‰å—",
           "å°æ¸¯", "å±æ±", "å´™èƒŒ", "å·¦ç‡Ÿ", "å¾©èˆˆ", "æ†æ˜¥", "æ–—å…­",
           "æ–°æ¸¯", "æ–°ç‡Ÿ", "æœ´å­", "æ—åœ’", "æ¥ æ¢“", "æ©‹é ­", "æ½®å·",
           "ç¾æ¿ƒ", "è‡ºå—", "è‡ºè¥¿", "é³³å±±"],
    "æ±": ["è‡ºæ±", "èŠ±è“®"]
}

# æ¸¬é …è³‡è¨Š
items_info = {
    "AMB_TEMP": {"name": "ç’°å¢ƒæº«åº¦", "unit": "Â°C"},
    "CO": {"name": "ä¸€æ°§åŒ–ç¢³", "unit": "ppm"},
    "NO": {"name": "ä¸€æ°§åŒ–æ°®", "unit": "ppb"},
    "NO2": {"name": "äºŒæ°§åŒ–æ°®", "unit": "ppb"},
    "NOx": {"name": "æ°®æ°§åŒ–ç‰©", "unit": "ppb"},
    "O3": {"name": "è‡­æ°§", "unit": "ppb"},
    "PM10": {"name": "æ‡¸æµ®å¾®ç²’", "unit": "Î¼g/mÂ³"},
    "PM2.5": {"name": "ç´°æ‡¸æµ®å¾®ç²’", "unit": "Î¼g/mÂ³"},
    "RAINFALL": {"name": "é™é›¨é‡", "unit": "mm"},
    "RH": {"name": "ç›¸å°æ¿•åº¦", "unit": "%"},
    "SO2": {"name": "äºŒæ°§åŒ–ç¡«", "unit": "ppb"},
    "WD_HR": {"name": "é¢¨å‘", "unit": "degrees"},
    "WIND_DIREC": {"name": "é¢¨å‘", "unit": "degrees"},
    "WIND_SPEED": {"name": "é¢¨é€Ÿ", "unit": "m/s"},
    "WS_HR": {"name": "å¹³å‡é¢¨é€Ÿ", "unit": "m/s"}
}

# ---------- å­—é«”è¨­å®š ----------
def set_chinese_font():
    p = "/usr/share/fonts/noto-cjk/NotoSansCJK-Regular.ttc"
    if os.path.exists(p):
        fontManager.addfont(p)
        prop = FontProperties(fname=p)
        found_name = prop.get_name()
        if found_name:
            mpl.rcParams['font.family'] = 'sans-serif'
            mpl.rcParams['font.sans-serif'] = [found_name]
            print(f"âœ… å­—é«”è¨­å®š: {found_name}")
            return found_name
    print("âš ï¸ ä½¿ç”¨é è¨­å­—é«”")
    return None

set_chinese_font()

# ---------- è¨ˆç®—å€åŸŸå¹³å‡ ----------
def calculate_regional_means(df):
    """è¨ˆç®—å„å€åŸŸçš„å¹³å‡å€¼"""
    df['datetime'] = pd.to_datetime(df['datetime'], errors='coerce')
    df = df.dropna(subset=['datetime'])
    
    regional_data = {}
    
    for region_name, region_sites in areas.items():
        mask = df['site'].isin(region_sites)
        if not mask.any():
            continue
        
        # è¨ˆç®—è©²å€åŸŸçš„å¹³å‡å€¼ï¼ˆæŒ‰ datetime å’Œ item åˆ†çµ„ï¼‰
        region_df = (df[mask]
                    .groupby(['datetime', 'item'], as_index=False)
                    ['value'].mean(numeric_only=True))
        region_df['region'] = region_name
        regional_data[region_name] = region_df
    
    if regional_data:
        return pd.concat(regional_data.values(), ignore_index=True)
    return pd.DataFrame()

# ---------- Tæª¢å®šåˆ†æ ----------
def perform_ttest_analysis(df, item):
    """å°å–®ä¸€æ¸¬é …é€²è¡Œæ‰€æœ‰å€åŸŸé–“çš„Tæª¢å®š"""
    item_data = df[df['item'] == item]
    regions = item_data['region'].unique()
    
    results = []
    
    # å…©å…©æ¯”è¼ƒæ‰€æœ‰å€åŸŸ
    for r1, r2 in combinations(regions, 2):
        data1 = item_data[item_data['region'] == r1]['value'].dropna()
        data2 = item_data[item_data['region'] == r2]['value'].dropna()
        
        if len(data1) < 2 or len(data2) < 2:
            continue
        
        # é€²è¡Œç¨ç«‹æ¨£æœ¬ T æª¢å®š
        t_stat, p_value = stats.ttest_ind(data1, data2)
        
        # è¨ˆç®—æ•ˆæ‡‰é‡ (Cohen's d)
        pooled_std = np.sqrt((data1.std()**2 + data2.std()**2) / 2)
        cohens_d = (data1.mean() - data2.mean()) / pooled_std if pooled_std > 0 else 0
        
        results.append({
            'item': item,
            'region_1': r1,
            'region_2': r2,
            'mean_1': data1.mean(),
            'mean_2': data2.mean(),
            'std_1': data1.std(),
            'std_2': data2.std(),
            'n_1': len(data1),
            'n_2': len(data2),
            't_statistic': t_stat,
            'p_value': p_value,
            'cohens_d': cohens_d,
            'significant': p_value < 0.05,
            'significance_level': '***' if p_value < 0.001 else '**' if p_value < 0.01 else '*' if p_value < 0.05 else 'ns'
        })
    
    return pd.DataFrame(results)

# ---------- ç¹ªè£½ç®±å‹åœ– ----------
def plot_boxplot(df, item, output_path):
    """ç¹ªè£½å„å€åŸŸçš„ç®±å‹åœ–æ¯”è¼ƒ"""
    item_data = df[df['item'] == item].copy()
    
    if item_data.empty:
        return
    
    info = items_info.get(item, {'name': item, 'unit': ''})
    
    fig, ax = plt.subplots(figsize=(12, 8))
    
    # ä½¿ç”¨ seaborn ç¹ªè£½ç®±å‹åœ–
    sns.boxplot(data=item_data, x='region', y='value', ax=ax, palette='Set2')
    sns.stripplot(data=item_data, x='region', y='value', ax=ax, 
                 color='black', alpha=0.3, size=2)
    
    ax.set_title(f"{info['name']} - å€åŸŸæ¯”è¼ƒ", fontsize=16, fontweight='bold')
    ax.set_xlabel("å€åŸŸ", fontsize=12)
    ax.set_ylabel(f"{info['name']} ({info['unit']})", fontsize=12)
    ax.grid(True, alpha=0.3, linestyle='--')
    
    plt.tight_layout()
    plt.savefig(output_path, dpi=150, bbox_inches='tight')
    plt.close(fig)

# ---------- ç¹ªè£½Tæª¢å®šç†±åœ– ----------
def plot_ttest_heatmap(ttest_results, item, output_path):
    """ç¹ªè£½Tæª¢å®špå€¼çš„ç†±åœ–"""
    if ttest_results.empty:
        return
    
    info = items_info.get(item, {'name': item, 'unit': ''})
    regions = sorted(set(ttest_results['region_1'].unique()) | 
                    set(ttest_results['region_2'].unique()))
    
    # å‰µå»ºpå€¼çŸ©é™£
    p_matrix = pd.DataFrame(1.0, index=regions, columns=regions)
    
    for _, row in ttest_results.iterrows():
        p_matrix.loc[row['region_1'], row['region_2']] = row['p_value']
        p_matrix.loc[row['region_2'], row['region_1']] = row['p_value']
    
    # å°è§’ç·šè¨­ç‚º NaNï¼ˆè‡ªå·±å’Œè‡ªå·±æ¯”è¼ƒï¼‰
    for r in regions:
        p_matrix.loc[r, r] = np.nan
    
    fig, ax = plt.subplots(figsize=(10, 8))
    
    # ä½¿ç”¨ -log10(p) ä¾†è¦–è¦ºåŒ–ï¼ˆè¶Šå¤§è¡¨ç¤ºè¶Šé¡¯è‘—ï¼‰
    plot_data = -np.log10(p_matrix.astype(float))
    
    sns.heatmap(plot_data, annot=p_matrix, fmt='.4f', cmap='RdYlGn_r', 
                center=1.3, vmin=0, vmax=3, ax=ax, cbar_kws={'label': '-log10(p-value)'})
    
    ax.set_title(f"{info['name']} - Tæª¢å®š På€¼ç†±åœ–\n(å€¼è¶Šå¤§è¶Šé¡¯è‘—, p<0.05ç‚ºé¡¯è‘—)", 
                fontsize=14, fontweight='bold')
    
    # æ·»åŠ é¡¯è‘—æ€§é–¾å€¼ç·š
    ax.axhline(y=0, color='red', linewidth=2, linestyle='--', alpha=0.5)
    ax.text(len(regions), 0.5, 'p=0.05', color='red', fontsize=10)
    
    plt.tight_layout()
    plt.savefig(output_path, dpi=150, bbox_inches='tight')
    plt.close(fig)

# ---------- ç”Ÿæˆçµ±è¨ˆå ±å‘Š ----------
def generate_report(all_results, output_path):
    """ç”Ÿæˆè©³ç´°çš„çµ±è¨ˆå ±å‘Š"""
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write("=" * 80 + "\n")
        f.write("AQI å€åŸŸé–“ Tæª¢å®šçµ±è¨ˆåˆ†æå ±å‘Š\n")
        f.write("=" * 80 + "\n\n")
        
        for item in all_results['item'].unique():
            item_results = all_results[all_results['item'] == item]
            info = items_info.get(item, {'name': item, 'unit': ''})
            
            f.write(f"\n{'='*80}\n")
            f.write(f"æ¸¬é …: {info['name']} ({item})\n")
            f.write(f"å–®ä½: {info['unit']}\n")
            f.write(f"{'='*80}\n\n")
            
            # å„å€åŸŸæè¿°çµ±è¨ˆ
            f.write("å€åŸŸæè¿°çµ±è¨ˆ:\n")
            f.write("-" * 80 + "\n")
            for region in item_results['region_1'].unique():
                region_data = item_results[item_results['region_1'] == region].iloc[0]
                f.write(f"  {region}: å¹³å‡={region_data['mean_1']:.2f}, "
                       f"æ¨™æº–å·®={region_data['std_1']:.2f}, "
                       f"æ¨£æœ¬æ•¸={region_data['n_1']}\n")
            f.write("\n")
            
            # Tæª¢å®šçµæœ
            f.write("Tæª¢å®šçµæœ (å…©å…©æ¯”è¼ƒ):\n")
            f.write("-" * 80 + "\n")
            significant_count = item_results['significant'].sum()
            f.write(f"ç¸½æ¯”è¼ƒæ¬¡æ•¸: {len(item_results)}\n")
            f.write(f"é¡¯è‘—å·®ç•°æ•¸: {significant_count} ({significant_count/len(item_results)*100:.1f}%)\n\n")
            
            # é¡¯è‘—å·®ç•°çš„é…å°
            sig_results = item_results[item_results['significant']].sort_values('p_value')
            if not sig_results.empty:
                f.write("é¡¯è‘—å·®ç•°çš„é…å°:\n")
                for _, row in sig_results.iterrows():
                    diff = row['mean_1'] - row['mean_2']
                    f.write(f"  {row['region_1']} vs {row['region_2']}: "
                           f"t={row['t_statistic']:.3f}, p={row['p_value']:.4f} {row['significance_level']}, "
                           f"å·®ç•°={diff:.2f}, Cohen's d={row['cohens_d']:.3f}\n")
            else:
                f.write("  ç„¡é¡¯è‘—å·®ç•°\n")
            
            f.write("\n")
        
        f.write("\n" + "=" * 80 + "\n")
        f.write("è¨»:\n")
        f.write("  *** : p < 0.001 (æ¥µé¡¯è‘—)\n")
        f.write("  **  : p < 0.01  (éå¸¸é¡¯è‘—)\n")
        f.write("  *   : p < 0.05  (é¡¯è‘—)\n")
        f.write("  ns  : p â‰¥ 0.05  (ä¸é¡¯è‘—)\n")
        f.write("  Cohen's d: æ•ˆæ‡‰é‡æŒ‡æ¨™ (|d|>0.8ç‚ºå¤§æ•ˆæ‡‰, 0.5-0.8ä¸­æ•ˆæ‡‰, 0.2-0.5å°æ•ˆæ‡‰)\n")
        f.write("=" * 80 + "\n")

# ---------- è™•ç†å–®æª” ----------
def process_file(file_path):
    """è™•ç†å–®ä¸€CSVæª”æ¡ˆ"""
    file_name = os.path.basename(file_path)
    file_base = os.path.splitext(file_name)[0]
    
    print(f"\nğŸ“Š è™•ç†: {file_name}")
    
    # è®€å–è³‡æ–™
    df_raw = pd.read_csv(file_path)
    
    # è¨ˆç®—å€åŸŸå¹³å‡
    print("  è¨ˆç®—å€åŸŸå¹³å‡...")
    regional_df = calculate_regional_means(df_raw)
    
    if regional_df.empty:
        print("  âš ï¸ ç„¡å€åŸŸè³‡æ–™")
        return
    
    # å‰µå»ºè¼¸å‡ºç›®éŒ„
    file_output_dir = os.path.join(output_dir, file_base)
    os.makedirs(file_output_dir, exist_ok=True)
    
    # å°æ¯å€‹æ¸¬é …é€²è¡Œåˆ†æ
    items = regional_df['item'].unique()
    all_results = []
    
    print(f"  åˆ†æ {len(items)} å€‹æ¸¬é …...")
    for item in tqdm(items, desc="  Tæª¢å®š", unit="é …"):
        # Tæª¢å®š
        ttest_results = perform_ttest_analysis(regional_df, item)
        
        if not ttest_results.empty:
            all_results.append(ttest_results)
            
            # ç¹ªè£½ç®±å‹åœ–
            boxplot_path = os.path.join(file_output_dir, f"{item}_boxplot.png")
            plot_boxplot(regional_df, item, boxplot_path)
            
            # ç¹ªè£½ç†±åœ–
            heatmap_path = os.path.join(file_output_dir, f"{item}_ttest_heatmap.png")
            plot_ttest_heatmap(ttest_results, item, heatmap_path)
    
    # åˆä½µæ‰€æœ‰çµæœ
    if all_results:
        all_results_df = pd.concat(all_results, ignore_index=True)
        
        # å„²å­˜CSV
        csv_path = os.path.join(file_output_dir, "ttest_results.csv")
        all_results_df.to_csv(csv_path, index=False, encoding='utf-8-sig')
        
        # ç”Ÿæˆå ±å‘Š
        report_path = os.path.join(file_output_dir, "statistical_report.txt")
        generate_report(all_results_df, report_path)
        
        print(f"  âœ… å®Œæˆ! è¼¸å‡ºè‡³: {file_output_dir}")
        print(f"     - {len(items)} å€‹æ¸¬é …")
        print(f"     - {len(all_results_df)} å€‹é…å°æ¯”è¼ƒ")
        print(f"     - {all_results_df['significant'].sum()} å€‹é¡¯è‘—å·®ç•°")

# ---------- ä¸»ç¨‹å¼ ----------
if __name__ == '__main__':
    print("=" * 80)
    print("AQI å€åŸŸé–“ Tæª¢å®šçµ±è¨ˆåˆ†æå·¥å…·")
    print("=" * 80)
    
    pattern = os.path.join(base_dir, 'hourly_2019*.csv')
    files = sorted(glob.glob(pattern))
    
    if not files:
        print("âš ï¸ æ‰¾ä¸åˆ°ç¬¦åˆæ¢ä»¶çš„æª”æ¡ˆ")
        exit(1)
    
    print(f"\nğŸ“ æ‰¾åˆ° {len(files)} å€‹æª”æ¡ˆ")
    
    # è™•ç†æ‰€æœ‰æª”æ¡ˆ
    for fp in tqdm(files, desc='è™•ç†æª”æ¡ˆ', unit='file'):
        try:
            process_file(fp)
        except Exception as e:
            tqdm.write(f"âŒ è™•ç†å¤±æ•— [{os.path.basename(fp)}]: {e}")
    
    print(f"\n{'='*80}")
    print(f"ğŸ‰ åˆ†æå®Œæˆ!")
    print(f"ğŸ“‚ çµæœç›®éŒ„: {output_dir}")
    print(f"{'='*80}")
    print("\nè¼¸å‡ºæª”æ¡ˆèªªæ˜:")
    print("  - *_boxplot.png : ç®±å‹åœ–ï¼ˆé¡¯ç¤ºå„å€åŸŸåˆ†å¸ƒï¼‰")
    print("  - *_ttest_heatmap.png : Tæª¢å®šç†±åœ–ï¼ˆé¡¯ç¤ºé¡¯è‘—æ€§ï¼‰")
    print("  - ttest_results.csv : å®Œæ•´çµ±è¨ˆçµæœ")
    print("  - statistical_report.txt : çµ±è¨ˆåˆ†æå ±å‘Š")
